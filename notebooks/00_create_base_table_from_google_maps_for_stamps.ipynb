{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Purpose\n",
    "* Create the base tracking tables for National Parks Passport Stamps\n",
    "* Pulled on February 3, 2025."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# GENERAL #\n",
    "import os\n",
    "import pathlib as pl\n",
    "import zipfile\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# ANALYSIS #\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "###############################################################################\n",
    "# LOCAL #\n",
    "\n",
    "ROOT_DIR = \"/Users/evancanfield/Documents/Projects/national_park_passport_stamps/\"\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google Map Export"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unzip KMZ File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KML file extracted to: /Users/evancanfield/Documents/Projects/national_park_passport_stamps/data/raw/national_park_passport_stamp_series_export_2025-02-03.kml\n"
     ]
    }
   ],
   "source": [
    "def kmz_to_kml(kmz_file, output_dir):\n",
    "    kmz_file_name = f'{kmz_file.stem}.kml'\n",
    "    with zipfile.ZipFile(kmz_file, 'r') as kmz:\n",
    "        for file in kmz.namelist():\n",
    "            if file.endswith('.kml'):\n",
    "                kml_content = kmz.read(file)\n",
    "                kml_path = pl.Path(output_dir, kmz_file_name)\n",
    "                with open(kml_path, 'wb') as kml_file:\n",
    "                    kml_file.write(kml_content)\n",
    "                print(f\"KML file extracted to: {kml_path}\")\n",
    "\n",
    "# Define path to kml file\n",
    "date_of_conversion = \"2025-02-03\"\n",
    "map_stem = f\"national_park_passport_stamp_series_export_{date_of_conversion}\"\n",
    "map_dir = pl.Path(ROOT_DIR, \"data\", \"raw\")\n",
    "map_kml_file = pl.Path(map_dir, f'{map_stem}.kml')\n",
    "map_kmz_file = pl.Path(map_dir, f'{map_stem}.kmz')\n",
    "\n",
    "if not map_kml_file.exists():\n",
    "\n",
    "    kmz_to_kml(map_kmz_file, map_kmz_file.parent)\n",
    "\n",
    "else:\n",
    "    print('KML File Aready Exists.')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read KML File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify all kml layers\n",
    "layers = gpd.list_layers(map_kml_file)\n",
    "\n",
    "# Init storage\n",
    "dct_map = {}\n",
    "\n",
    "\n",
    "for layer in layers['name'].unique():\n",
    "    dct_map[layer] = gpd.read_file(\n",
    "        map_kml_file,\n",
    "        layer = layer\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visited Parks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "visited_path = pl.Path(\n",
    "    ROOT_DIR,\n",
    "    'data',\n",
    "    'raw',\n",
    "    f'national_park_passport_stamp_series_visited_{date_of_conversion}.csv'\n",
    ")\n",
    "\n",
    "df_visited = pd.read_csv(visited_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Up Google Map Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "National\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "North Atlantic\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Mid-Atlantic\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Southeast\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Midwest\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Southwest\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Rocky Mountain\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Western\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Pacific Northwest & Alaska\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize varaiables\n",
    "frames = []\n",
    "drop_cols = ['description', 'geometry']\n",
    "\n",
    "\n",
    "for region, gdf in dct_map.items():\n",
    "    print(80 * '-')\n",
    "    print(region)\n",
    "    print()\n",
    "\n",
    "    # Set columns to lower case\n",
    "    cols = gdf.columns\n",
    "    gdf.columns = [col.lower() for col in cols]\n",
    "\n",
    "    # Extract year\n",
    "    gdf['year'] = gdf['name'].apply(\n",
    "        lambda x: int(x.split('-')[0])\n",
    "    )\n",
    "\n",
    "    # Extract name\n",
    "    gdf['name'] = gdf['name'].apply(\n",
    "        lambda x: x.split(' - ')[-1]\n",
    "    )\n",
    "\n",
    "    # Remove (1/5) (1988 National Stickers)\n",
    "    gdf['name'] = gdf['name'].apply(\n",
    "        lambda x: x.replace(\"(1/5)\", \"\")\n",
    "    )\n",
    "\n",
    "    # Latitude\n",
    "    gdf['latitude'] = gdf['geometry'].apply(\n",
    "        lambda x: x.y\n",
    "    )\n",
    "\n",
    "    # Longitude\n",
    "    gdf['longitude'] = gdf['geometry'].apply(\n",
    "        lambda x: x.x\n",
    "    )\n",
    "\n",
    "    # Convert to dataframe and drop select columns\n",
    "    df = pd.DataFrame(gdf).drop(columns = drop_cols)\n",
    "\n",
    "    # Assin region to a column\n",
    "    df['region'] = region\n",
    "\n",
    "    frames.append(df)\n",
    "\n",
    "df_stamps = pd.concat(frames)\n",
    "\n",
    "# Sort by Year and Name\n",
    "df_stamps = df_stamps.sort_values(\n",
    "    ['region', 'year', 'name'], \n",
    "    ascending=[True, True, True]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>year</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Colonial National Historical Park</td>\n",
       "      <td>1986</td>\n",
       "      <td>37.229134</td>\n",
       "      <td>-76.503903</td>\n",
       "      <td>Mid-Atlantic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hopewell Furnace National Historic Site</td>\n",
       "      <td>1987</td>\n",
       "      <td>40.209727</td>\n",
       "      <td>-75.769126</td>\n",
       "      <td>Mid-Atlantic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Gettysburg National Military Park</td>\n",
       "      <td>1988</td>\n",
       "      <td>39.810644</td>\n",
       "      <td>-77.227106</td>\n",
       "      <td>Mid-Atlantic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Assateague Island National Seashore</td>\n",
       "      <td>1989</td>\n",
       "      <td>38.060797</td>\n",
       "      <td>-75.236238</td>\n",
       "      <td>Mid-Atlantic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Appomattox Court House National Historical Park</td>\n",
       "      <td>1990</td>\n",
       "      <td>37.377520</td>\n",
       "      <td>-78.796007</td>\n",
       "      <td>Mid-Atlantic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Pu'ukohola Heiau National Historic Site</td>\n",
       "      <td>2021</td>\n",
       "      <td>20.025629</td>\n",
       "      <td>-155.821777</td>\n",
       "      <td>Western</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Great Basin National Park</td>\n",
       "      <td>2022</td>\n",
       "      <td>38.929980</td>\n",
       "      <td>-114.263379</td>\n",
       "      <td>Western</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Pipe Spring National Monument</td>\n",
       "      <td>2023</td>\n",
       "      <td>36.862533</td>\n",
       "      <td>-112.737463</td>\n",
       "      <td>Western</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Wupatki National Monument</td>\n",
       "      <td>2024</td>\n",
       "      <td>35.559984</td>\n",
       "      <td>-111.393527</td>\n",
       "      <td>Western</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>John Muir National Historic Site</td>\n",
       "      <td>2025</td>\n",
       "      <td>37.992166</td>\n",
       "      <td>-122.131068</td>\n",
       "      <td>Western</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>363 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               name  year   latitude  \\\n",
       "0                 Colonial National Historical Park  1986  37.229134   \n",
       "1           Hopewell Furnace National Historic Site  1987  40.209727   \n",
       "34                Gettysburg National Military Park  1988  39.810644   \n",
       "2               Assateague Island National Seashore  1989  38.060797   \n",
       "35  Appomattox Court House National Historical Park  1990  37.377520   \n",
       "..                                              ...   ...        ...   \n",
       "30          Pu'ukohola Heiau National Historic Site  2021  20.025629   \n",
       "31                        Great Basin National Park  2022  38.929980   \n",
       "32                    Pipe Spring National Monument  2023  36.862533   \n",
       "33                        Wupatki National Monument  2024  35.559984   \n",
       "34                 John Muir National Historic Site  2025  37.992166   \n",
       "\n",
       "     longitude        region  \n",
       "0   -76.503903  Mid-Atlantic  \n",
       "1   -75.769126  Mid-Atlantic  \n",
       "34  -77.227106  Mid-Atlantic  \n",
       "2   -75.236238  Mid-Atlantic  \n",
       "35  -78.796007  Mid-Atlantic  \n",
       "..         ...           ...  \n",
       "30 -155.821777       Western  \n",
       "31 -114.263379       Western  \n",
       "32 -112.737463       Western  \n",
       "33 -111.393527       Western  \n",
       "34 -122.131068       Western  \n",
       "\n",
       "[363 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stamps"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine Region Maps into Single Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Visited Parks:\n",
      "-- Visited List:\t52\n",
      "-- Stamp Table:\t\t52\n"
     ]
    }
   ],
   "source": [
    "# Determine which parks were visited\n",
    "visited_parks = df_visited['name'].to_list()\n",
    "visited_parks = [\n",
    "    park \\\n",
    "        .split(' - ')[-1] \\\n",
    "        .replace('\\xa0(1/5)', '') \\\n",
    "        \n",
    "    for park in visited_parks\n",
    "    ]\n",
    "\n",
    "visited_parks = sorted(visited_parks)\n",
    "\n",
    "# Create boolean column for determining visited parks\n",
    "df_stamps['visited'] = df_stamps['name'].apply(\n",
    "    lambda x: 'Yes' if x in visited_parks else 'No'\n",
    ")\n",
    "\n",
    "# Count number of parks visited\n",
    "n_parks = int(df_stamps['visited'].value_counts().get(\"Yes\"))\n",
    "\n",
    "# Check visited matching worked\n",
    "print('Number of Visited Parks:') \n",
    "print(f'-- Visited List:\\t{len(visited_parks):,}')\n",
    "print(f'-- Stamp Table:\\t\\t{n_parks:,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Mid-Atlantic', 'Midwest', 'National', 'North Atlantic',\n",
       "       'Pacific Northwest & Alaska', 'Rocky Mountain', 'Southeast',\n",
       "       'Southwest', 'Western'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stamps['region'].unique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data_dir = pl.Path(ROOT_DIR, \"data\", \"processed\")\n",
    "stamp_table_name = f\"national_park_passport_stamp_series_export_{date_of_conversion}.csv\"\n",
    "stamp_table_path = pl.Path(processed_data_dir, stamp_table_name)\n",
    "\n",
    "df_stamps.to_csv(stamp_table_path, index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".national_park_passport_stamps",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
